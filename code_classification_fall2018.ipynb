{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### INCLUSION CRITERIA ANALYSIS###\n",
    "####The below code \n",
    "#Creators: Xiaoru Dong\n",
    "#Contributors:\n",
    "#Last updated: 12/10/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign spreadsheet filename to `file`\n",
    "file = '/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/Annotations_All.xlsx'\n",
    "\n",
    "# Load spreadsheet\n",
    "xl = pd.ExcelFile(file)\n",
    "\n",
    "# Load a sheet into a DataFrame by name: df1\n",
    "df = xl.parse('All Inclusion Criteria (5420)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The list of stop words\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \n",
    "              \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", \n",
    "              'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "              'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', \n",
    "              'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', \n",
    "              'the', 'if', 'because', 'as', 'until', 'of', 'at', 'by', 'for', 'with', 'about', 'between', 'into',\n",
    "              'through', 'during', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', \n",
    "              'under', 'again', 'further', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'few', 'more', \n",
    "              'most', 'some', 'such', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', \n",
    "              'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineNum = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set a function for outputing features\n",
    "def writefeatures(path, features):\n",
    "    with open(path,\"w\") as fp: \n",
    "        for word in features:\n",
    "            fp.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get an arff file used as the input in Weka\n",
    "def writewekainput(path, features, lineNum, eachline, rct):\n",
    "    with open(path,\"w\") as fp:        #this line of code to create a new file\n",
    "        fp.write('''@RELATION classification_analysis\\n''')\n",
    "    \n",
    "        for i in range(len(features)): \n",
    "            fp.write('''@ATTRIBUTE ''' + \"word\" + str(i) + ''' NUMERIC\\n''') \n",
    "    \n",
    "        fp.write('''@ATTRIBUTE class {1.0, 0.0}\\n''')\n",
    "        fp.write('''@DATA\\n''')\n",
    "\n",
    "    #this code is to check if a word appear in the feature list or not. If yes, then write \"1\", if no then write \"0\"\n",
    "    \n",
    "        for i in range(lineNum): \n",
    "            binary = {}\n",
    "            for word in features:\n",
    "                if word in eachline[i]:\n",
    "                    binary[word] = 1\n",
    "                else:\n",
    "                    binary[word] = 0\n",
    "                fp.write(str(binary[word]) + \",\")\n",
    "            fp.write(rct[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results1 = []\n",
    "wordlist = []\n",
    "rct = []\n",
    "eachline = []\n",
    "\n",
    "# split the sentence into words and save in a list\n",
    "for i in range(lineNum): \n",
    "    \n",
    "    string_rct = str(df['Only RCTs'][i])\n",
    "    if string_rct == 'nan':\n",
    "        string_rct = '0.0'\n",
    "    if string_rct == 'x':\n",
    "        string_rct = '1.0'\n",
    "    rct.append(string_rct)\n",
    "    \n",
    "    string = str(df['Inclusion Criteria'][i]).lower().strip()\n",
    "    wordlist = string.split(' ')\n",
    "    \n",
    "    for j in range(len(wordlist)):\n",
    "        wordlist[j] = wordlist[j].replace('.', '')\n",
    "        wordlist[j] = wordlist[j].replace(')', '')\n",
    "        wordlist[j] = wordlist[j].replace('(', '')\n",
    "        wordlist[j] = wordlist[j].replace(',', '')\n",
    "        wordlist[j] = wordlist[j].replace(\"'\", '')\n",
    "        wordlist[j] = wordlist[j].replace('\"', '')\n",
    "        results1.append(wordlist[j])\n",
    "    eachline.append(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7292"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove empty element in the list\n",
    "results1 = list(OrderedDict.fromkeys(results1))\n",
    "results1 = [x for x in results1 if x] \n",
    "len(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7202"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words\n",
    "results1 = [word for word in results1 if word not in stop_words]\n",
    "len(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output features\n",
    "featureword0_savepath = \"/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/word_bag_0.txt\"\n",
    "writefeatures(featureword0_savepath, results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the weka input file\n",
    "weka0_path=\"/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/classification_fall_weka_input_0.arff\"\n",
    "writewekainput(weka0_path, results1, lineNum, eachline, rct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract Features using information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign spreadsheet filename to `file`\n",
    "file = '/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/WekaResult/InfoWords.xlsx'\n",
    "\n",
    "# Load spreadsheet\n",
    "x2 = pd.ExcelFile(file)\n",
    "\n",
    "# Load a sheet into a DataFrame by name: df2\n",
    "df2 = x2.parse('InfoWords0')\n",
    "df3 = x2.parse('InfoWords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the informative words and save them in a list\n",
    "info_wordlist = []\n",
    "for word in (df2['Word Code in Weka']-1):\n",
    "    info_wordlist.append(results1[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output features\n",
    "featureinfoword0_savepath = \"/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/InfoWord/informative_words_0.txt\"\n",
    "writefeatures(featureinfoword0_savepath, info_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the weka input file\n",
    "wekainfo0_path=\"/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/InfoWord/classification_fall_weka_input_info_0.arff\"\n",
    "writewekainput(wekainfo0_path, info_wordlist, lineNum, eachline, rct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove same meaning words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results2 = []\n",
    "wordlist2 = []\n",
    "rct = []\n",
    "eachline2 = []\n",
    "\n",
    "#replace the same meaning words\n",
    "quasi = ['quasi-rcts', 'quasi-randomized', 'quasi-randomised', 'quasi-random', 'quasi-randomly']\n",
    "cct = ['cct', 'ccts']\n",
    "cba = ['cba', 'cbas', 'before-after']\n",
    "privative = [\"not\",\"didn't\", \"don't\", \"won't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"needn't\", \"wouldn't\", \"shouldn't\", \"can't\", \"couldn't\", \"no\"]\n",
    "\n",
    "# split the sentence into words and save in a list\n",
    "for i in range(lineNum): \n",
    "    \n",
    "    string_rct = str(df['Only RCTs'][i])\n",
    "    if string_rct == 'nan':\n",
    "        string_rct = '0.0'\n",
    "    if string_rct == 'x':\n",
    "        string_rct = '1.0'\n",
    "    rct.append(string_rct)\n",
    "    \n",
    "    string = str(df['Inclusion Criteria'][i]).lower().strip()\n",
    "    wordlist2 = string.split(' ')\n",
    "    \n",
    "    for j in range(len(wordlist2)):\n",
    "        wordlist2[j] = wordlist2[j].replace('.', '')\n",
    "        wordlist2[j] = wordlist2[j].replace(')', '')\n",
    "        wordlist2[j] = wordlist2[j].replace('(', '')\n",
    "        wordlist2[j] = wordlist2[j].replace(',', '')\n",
    "        wordlist2[j] = wordlist2[j].replace(\"'\", '')\n",
    "        wordlist2[j] = wordlist2[j].replace('\"', '')\n",
    "        if wordlist2[j] in quasi:\n",
    "            wordlist2[j] = 'quasi-rcts'\n",
    "        if wordlist2[j] in cct:\n",
    "            wordlist2[j] = 'cct'\n",
    "        if wordlist2[j] in cba:\n",
    "            wordlist2[j] = 'cba'\n",
    "        if wordlist2[j] in privative:\n",
    "            wordlist2[j] = 'not'\n",
    "        results2.append(wordlist2[j])\n",
    "    eachline2.append(wordlist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7194"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = list(OrderedDict.fromkeys(results2))\n",
    "results2 = [x for x in results2 if x] #remove empty element in the list\n",
    "results2 = [word for word in results2 if word not in stop_words]\n",
    "len(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output features\n",
    "featureinfoword_savepath = \"/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/word_bag.txt\"\n",
    "writefeatures(featureinfoword_savepath, results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the weka input file\n",
    "weka_path=\"/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/classification_fall_weka_input.arff\"\n",
    "writewekainput(weka_path, results2, lineNum, eachline2, rct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# infomative words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the informative words and save them in a list\n",
    "info_wordlist = []\n",
    "for word in (df3['Word Code in Weka']-1):\n",
    "    info_wordlist.append(results2[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1655"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output features\n",
    "featureinfoword_savepath = \"/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/InfoWord/informative_words.txt\"\n",
    "writefeatures(featureinfoword_savepath, info_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the weka input file\n",
    "wekainfo_path=\"/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/InfoWord/classification_fall_weka_input_info.arff\"\n",
    "writewekainput(wekainfo_path, info_wordlist, lineNum, eachline2, rct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign spreadsheet filename to `file`\n",
    "file = '/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/DataFile.xlsx'\n",
    "\n",
    "# Load spreadsheet\n",
    "x3 = pd.ExcelFile(file)\n",
    "\n",
    "# Load a sheet into a DataFrame by name: df2\n",
    "df4 = x3.parse('Informative Words2 (407)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quasi-rcts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alternation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allocation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>looking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>double-blind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>determination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>record</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>excluded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>obtained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>strictly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>interrupted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cohort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>substantive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>eg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>implied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ibuprofen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>defined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>case-control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>galactomannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>deviations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>aggregation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>jurisdiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>polyglactin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>knew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>pointwhilst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>â€˜delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>collated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>feverfew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>pet-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>urate-lowering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>existing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>so-called</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>non-controlled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>rct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>identified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>non-inferiority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>persons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>starting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>broadband</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>eating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>considered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>section</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>non-randomized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word\n",
       "0         quasi-rcts\n",
       "1              birth\n",
       "2        alternation\n",
       "3                and\n",
       "4               date\n",
       "5            methods\n",
       "6                cct\n",
       "7         allocation\n",
       "8                 or\n",
       "9            looking\n",
       "10      double-blind\n",
       "11     determination\n",
       "12            record\n",
       "13          excluded\n",
       "14            series\n",
       "15            number\n",
       "16            random\n",
       "17          obtained\n",
       "18          strictly\n",
       "19       interrupted\n",
       "20            cohort\n",
       "21              time\n",
       "22       substantive\n",
       "23                eg\n",
       "24           implied\n",
       "25         ibuprofen\n",
       "26           defined\n",
       "27      case-control\n",
       "28     galactomannan\n",
       "29        deviations\n",
       "..               ...\n",
       "377      aggregation\n",
       "378     jurisdiction\n",
       "379      polyglactin\n",
       "380             knew\n",
       "381              say\n",
       "382      pointwhilst\n",
       "383       â€˜delayed\n",
       "384         collated\n",
       "385         feverfew\n",
       "386           pet-ct\n",
       "387   urate-lowering\n",
       "388            excel\n",
       "389         existing\n",
       "390        so-called\n",
       "391   non-controlled\n",
       "392              rct\n",
       "393          present\n",
       "394              oct\n",
       "395       identified\n",
       "396  non-inferiority\n",
       "397          persons\n",
       "398         starting\n",
       "399        broadband\n",
       "400           eating\n",
       "401       considered\n",
       "402          section\n",
       "403            units\n",
       "404   non-randomized\n",
       "405            order\n",
       "406             risk\n",
       "\n",
       "[407 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the informative words and save them in a list\n",
    "info_wordlist = []\n",
    "for word in df4['Word']:\n",
    "    info_wordlist.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output the weka input file\n",
    "wekainfo3_path=\"/Users/ruby/Desktop/Research/InclusionCriteriaClassification/Fall/InfoWord/classification_fall_weka_input_info_3.arff\"\n",
    "writewekainput(wekainfo3_path, info_wordlist, lineNum, eachline2, rct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
